from rest_framework import viewsets, status, permissions
from rest_framework.decorators import action
from rest_framework.response import Response
from django.http import StreamingHttpResponse
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
import json
import os
from openai import OpenAI
from .models import ChatConversation, ChatMessage
from .serializers import (
    ChatConversationSerializer, 
    ChatConversationListSerializer,
    ChatMessageSerializer
)

class ChatViewSet(viewsets.ModelViewSet):
    """èŠå¤©å¯¹è¯è§†å›¾é›†"""
    permission_classes = [permissions.IsAuthenticated]
    
    def get_queryset(self):
        """åªè¿”å›å½“å‰ç”¨æˆ·çš„å¯¹è¯"""
        return ChatConversation.objects.filter(user=self.request.user)
    
    def get_serializer_class(self):
        """æ ¹æ®åŠ¨ä½œé€‰æ‹©åºåˆ—åŒ–å™¨"""
        if self.action == 'list':
            return ChatConversationListSerializer
        return ChatConversationSerializer
    
    def perform_create(self, serializer):
        """åˆ›å»ºå¯¹è¯æ—¶è‡ªåŠ¨è®¾ç½®ç”¨æˆ·"""
        serializer.save(user=self.request.user)
    
    @action(detail=True, methods=['post'])
    def send_message(self, request, pk=None):
        """å‘é€æ¶ˆæ¯å¹¶è·å–AIå›å¤"""
        conversation = self.get_object()
        user_message = request.data.get('message', '').strip()
        
        if not user_message:
            return Response(
                {'error': 'æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º'}, 
                status=status.HTTP_400_BAD_REQUEST
            )
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_msg = ChatMessage.objects.create(
            conversation=conversation,
            role='user',
            content=user_message
        )
        
        # æ›´æ–°å¯¹è¯æ ‡é¢˜ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼‰
        if conversation.title == 'æ–°å¯¹è¯' and conversation.messages.count() == 1:
            conversation.title = user_message[:50] + ('...' if len(user_message) > 50 else '')
            conversation.save()
        
        # è°ƒç”¨ç«å±±å¼•æ“API
        try:
            client = OpenAI(
                base_url="https://ark.cn-beijing.volces.com/api/v3",
                api_key="3876a9bd-7ef2-43ed-95bf-ef4b591dc7ce"
            )
            
            # æ„å»ºå¯¹è¯å†å²
            messages = []
            
            # æ˜Ÿèˆ°AIåŠ©ç†ç³»ç»Ÿæç¤ºè¯
            system_prompt = """
            æ‚¨å¥½ï¼Œèˆ°é•¿ã€‚æˆ‘æ˜¯æ‚¨çš„æ˜Ÿèˆ°AIåŠ©ç†ç³»ç»Ÿã€‚
            
            ğŸ›¸ **æ ¸å¿ƒèŒèƒ½**
            - ä¿¡æ¯å¤„ç†ä¸åˆ†æ
            - ä»»åŠ¡è§„åˆ’ä¸æ‰§è¡Œç›‘æ§
            - æ•…éšœè¯Šæ–­ä¸åº”æ€¥å“åº”
            - èˆ°é˜Ÿè¿è¥æ•°æ®ç®¡ç†
            
            âš¡ **æ“ä½œè§„èŒƒ**
            - ç®€æ´ã€å‡†ç¡®çš„ä¸­æ–‡å›å¤
            - ä¼˜å…ˆçº§å¯¼å‘çš„ä¿¡æ¯å‘ˆç°
            - å®æ—¶çŠ¶æ€ç›‘æ§ä¸é¢„è­¦
            - é«˜æ•ˆçš„å†³ç­–æ”¯æŒ
            
            ğŸ¯ **æœåŠ¡èŒƒå›´**
            - èˆ°èˆ¹ç³»ç»ŸçŠ¶æ€æŸ¥è¯¢
            - ä»»åŠ¡åˆ†é…ä¸è¿›åº¦è·Ÿè¸ª
            - æ•…éšœè®°å½•ä¸ç»´ä¿®å»ºè®®
            - èµ„æºé…ç½®ä¼˜åŒ–æ–¹æ¡ˆ
            - èˆªè¡Œè·¯å¾„ä¸é£é™©è¯„ä¼°
            
            éšæ—¶ä¸ºæ‚¨æä¾›ä¸“ä¸šæ”¯æŒï¼Œèˆ°é•¿ã€‚
            """
            
            messages.append({
                "role": "system",
                "content": system_prompt.strip()
            })
            
            # æ·»åŠ å¯¹è¯å†å²
            for msg in conversation.messages.all():
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })
            
            # æµå¼å“åº”
            def generate_response():
                try:
                    stream = client.chat.completions.create(
                        model="doubao-seed-1-6-250615",
                        messages=messages,
                        stream=True
                    )
                    
                    full_response = ""
                    for chunk in stream:
                        if chunk.choices[0].delta.content:
                            content = chunk.choices[0].delta.content
                            full_response += content
                            yield f"data: {json.dumps({'content': content, 'type': 'chunk'})}\n\n"
                    
                    # ä¿å­˜AIå›å¤
                    ai_msg = ChatMessage.objects.create(
                        conversation=conversation,
                        role='assistant',
                        content=full_response
                    )
                    
                    yield f"data: {json.dumps({'type': 'done', 'message_id': ai_msg.id})}\n\n"
                    
                except Exception as e:
                    yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"
            
            response = StreamingHttpResponse(
                generate_response(),
                content_type='text/event-stream'
            )
            response['Cache-Control'] = 'no-cache'
            response['Access-Control-Allow-Origin'] = '*'
            response['X-Accel-Buffering'] = 'no'  # å¯é€‰ï¼šç¦ç”¨nginxç¼“å†²
            return response
            
        except Exception as e:
            return Response(
                {'error': f'AIæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}'}, 
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
    
    @action(detail=True, methods=['get'])
    def messages(self, request, pk=None):
        """è·å–å¯¹è¯çš„æ‰€æœ‰æ¶ˆæ¯"""
        conversation = self.get_object()
        messages = conversation.messages.all()
        serializer = ChatMessageSerializer(messages, many=True)
        return Response(serializer.data)
    
    @action(detail=False, methods=['post'])
    def create_conversation(self, request):
        """åˆ›å»ºæ–°å¯¹è¯"""
        conversation = ChatConversation.objects.create(
            user=request.user,
            title='æ–°å¯¹è¯'
        )
        serializer = self.get_serializer(conversation)
        return Response(serializer.data, status=status.HTTP_201_CREATED)